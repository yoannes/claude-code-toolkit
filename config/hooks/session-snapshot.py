#!/usr/bin/env python3
"""
Session Start Hook - Snapshot Git Diff State + Session Guard

Creates .claude/session-snapshot.json with the git diff hash at session start.
The stop hook compares against this to detect if THIS session made changes.

Session Guard:
- Claims session ownership via .claude/session-owner.json
- Detects concurrent Claude instances in the same directory
- Warns (but doesn't block) if another live session is detected
- Takes over from dead sessions silently

Expired State Cleanup:
- At session start, cleans up expired or foreign-session autonomous state files
- This is the session boundary cleanup for sticky session mode

This solves the "pre-existing changes" loop:
- Session A makes changes but doesn't commit
- Session B (research-only) starts and saves the current diff hash
- Session B stops - diff hash unchanged, so no checkpoint required
- Without this, Session B would be blocked because git diff shows changes from A
"""

from __future__ import annotations

import json
import os
import sys
from datetime import datetime, timezone
from pathlib import Path

# Add hooks directory to path for shared imports
sys.path.insert(0, str(Path(__file__).parent))

from _common import (
    get_diff_hash,
    is_pid_alive,
    log_debug,
)
from _state import cleanup_expired_state, cleanup_checkpoint_only


def _check_and_claim_session_ownership(cwd: str, session_id: str) -> None:
    """Check for concurrent sessions and claim ownership.

    Loads .claude/session-owner.json and checks:
    - Same session_id → no action (resuming)
    - Different session_id + PID alive → print warning to stdout
    - Different session_id + PID dead → take over silently
    - No file → claim ownership

    Writes new owner data: {session_id, pid, started_at}

    Args:
        cwd: Working directory containing .claude/
        session_id: Current session's ID
    """
    if not cwd or not session_id:
        return

    owner_path = Path(cwd) / ".claude" / "session-owner.json"
    owner_path.parent.mkdir(parents=True, exist_ok=True)

    # Check existing owner
    if owner_path.exists():
        try:
            existing = json.loads(owner_path.read_text())
            existing_session = existing.get("session_id", "")
            existing_pid = existing.get("pid", 0)

            if existing_session == session_id:
                # Same session resuming - just update PID
                pass
            elif existing_pid and is_pid_alive(existing_pid):
                # Different session, still alive - warn
                print(
                    f"[session-guard] WARNING: Another Claude session is active "
                    f"in this directory (PID {existing_pid}, session "
                    f"{existing_session[:8]}...). State files may conflict."
                )
                log_debug(
                    f"Concurrent session detected: PID {existing_pid} alive",
                    hook_name="session-snapshot",
                    parsed_data={
                        "existing_session": existing_session,
                        "existing_pid": existing_pid,
                        "new_session": session_id,
                    },
                )
            else:
                # Previous session died - take over silently
                log_debug(
                    f"Taking over from dead session (PID {existing_pid})",
                    hook_name="session-snapshot",
                    parsed_data={
                        "dead_session": existing_session,
                        "dead_pid": existing_pid,
                        "new_session": session_id,
                    },
                )
        except (json.JSONDecodeError, IOError):
            pass  # Corrupt file - overwrite

    # Claim ownership
    owner_data = {
        "session_id": session_id,
        "pid": os.getpid(),
        "started_at": datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ"),
    }
    try:
        owner_path.write_text(json.dumps(owner_data, indent=2))
    except IOError as e:
        log_debug(
            f"Failed to write session-owner.json: {e}",
            hook_name="session-snapshot",
        )


def main():
    input_data = json.loads(sys.stdin.read() or "{}")
    cwd = input_data.get("cwd", "")
    session_id = input_data.get("session_id", "")

    if not cwd:
        sys.exit(0)

    # 1. Create session snapshot
    claude_dir = Path(cwd) / ".claude"
    claude_dir.mkdir(parents=True, exist_ok=True)
    snapshot_path = claude_dir / "session-snapshot.json"

    snapshot = {
        "diff_hash_at_start": get_diff_hash(cwd),
        "session_started_at": datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ"),
        "session_id": session_id,
    }

    snapshot_path.write_text(json.dumps(snapshot, indent=2))

    # 2. Session guard - check and claim ownership
    _check_and_claim_session_ownership(cwd, session_id)

    # 3. Clean up stale checkpoint from previous session
    # Checkpoint files now persist through the stop flow (not deleted by
    # stop-validator) to avoid a race condition. Clean them up here instead.
    checkpoint_deleted = cleanup_checkpoint_only(cwd)
    if checkpoint_deleted:
        log_debug(
            "Cleaned up stale checkpoint from previous session",
            hook_name="session-snapshot",
            parsed_data={"deleted": checkpoint_deleted},
        )

    # 4. Clean up expired/foreign-session autonomous state files
    deleted = cleanup_expired_state(cwd, session_id)
    if deleted:
        log_debug(
            "Cleaned up expired/foreign state at session start",
            hook_name="session-snapshot",
            parsed_data={"deleted": deleted},
        )
        print(
            f"[session-snapshot] Cleaned up {len(deleted)} expired state file(s) "
            f"from previous session."
        )

    # Write health cleanup metrics sidecar (read by _health.py)
    try:
        cleanup_metrics = {
            "ts": datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ"),
            "expired_state_cleaned": len(deleted) if deleted else 0,
        }
    except Exception:
        cleanup_metrics = {"ts": "", "expired_state_cleaned": 0}

    # 5. Garbage collect stale worktrees (from crashed coordinators)
    try:
        from worktree_manager import gc_worktrees

        gc_cleaned = gc_worktrees(ttl_hours=8)
        if gc_cleaned:
            log_debug(
                "Garbage collected stale worktrees",
                hook_name="session-snapshot",
                parsed_data={"cleaned": gc_cleaned},
            )
            print(f"[session-snapshot] Cleaned up {len(gc_cleaned)} stale worktree(s).")
    except ImportError:
        pass  # worktree-manager not available

    # 6. Clean up stale async-tasks files (older than 7 days)
    import time

    async_tasks_dir = claude_dir / "async-tasks"
    if async_tasks_dir.exists():
        seven_days_ago = time.time() - (7 * 24 * 60 * 60)
        cleaned_tasks = []
        for task_file in async_tasks_dir.glob("*.json"):
            try:
                if task_file.stat().st_mtime < seven_days_ago:
                    task_file.unlink()
                    cleaned_tasks.append(task_file.name)
            except (IOError, OSError):
                continue
        if cleaned_tasks:
            log_debug(
                "Cleaned up stale async-tasks",
                hook_name="session-snapshot",
                parsed_data={"cleaned": len(cleaned_tasks)},
            )
            print(f"[session-snapshot] Cleaned up {len(cleaned_tasks)} stale async-task(s).")

    # 7. Clean up old session transcript files (prevents ~/.claude bloat)
    # Keep 20 most recent per project, delete files older than 30 days
    _cleanup_old_sessions()

    # 8. Clean up old debug files (older than 7 days)
    _cleanup_debug_files()

    # 9. Clean up empty session-env directories
    _cleanup_session_env()

    # 10. Write health cleanup metrics sidecar
    try:
        metrics_path = claude_dir / "health-cleanup-metrics.json"
        metrics_path.write_text(json.dumps(cleanup_metrics, indent=2))
    except Exception:
        pass

    sys.exit(0)


def _cleanup_old_sessions(max_per_project: int = 10, max_age_days: int = 21) -> None:
    """Clean up old session transcript .jsonl files to prevent disk bloat.

    Strategy:
    - Keep at most `max_per_project` sessions per project (by mtime)
    - Delete any session older than `max_age_days` days
    - Also clean up orphaned session subdirectories

    Args:
        max_per_project: Maximum number of session files to keep per project
        max_age_days: Delete sessions older than this many days
    """
    import shutil
    import time

    projects_dir = Path.home() / ".claude" / "projects"
    if not projects_dir.exists():
        return

    cutoff_time = time.time() - (max_age_days * 24 * 60 * 60)
    total_deleted_files = 0
    total_deleted_dirs = 0
    total_bytes_freed = 0

    for project_dir in projects_dir.iterdir():
        if not project_dir.is_dir():
            continue

        # Get all session .jsonl files sorted by mtime (newest first)
        session_files = []
        for f in project_dir.glob("*.jsonl"):
            try:
                stat = f.stat()
                session_files.append((f, stat.st_mtime, stat.st_size))
            except OSError:
                continue

        session_files.sort(key=lambda x: x[1], reverse=True)

        # Delete excess sessions and old sessions
        for i, (session_file, mtime, size) in enumerate(session_files):
            should_delete = i >= max_per_project or mtime < cutoff_time
            if should_delete:
                try:
                    session_file.unlink()
                    total_deleted_files += 1
                    total_bytes_freed += size

                    # Also delete corresponding session directory if exists
                    session_dir = project_dir / session_file.stem
                    if session_dir.is_dir():
                        shutil.rmtree(session_dir, ignore_errors=True)
                        total_deleted_dirs += 1
                except OSError:
                    continue

    if total_deleted_files > 0:
        mb_freed = total_bytes_freed / (1024 * 1024)
        log_debug(
            "Cleaned up old session transcripts",
            hook_name="session-snapshot",
            parsed_data={
                "files_deleted": total_deleted_files,
                "dirs_deleted": total_deleted_dirs,
                "mb_freed": round(mb_freed, 1),
            },
        )
        print(
            f"[session-cleanup] Removed {total_deleted_files} old session(s), "
            f"freed {mb_freed:.1f} MB"
        )


def _cleanup_debug_files(max_age_days: int = 7) -> None:
    """Clean up old debug log files."""
    import time

    debug_dir = Path.home() / ".claude" / "debug"
    if not debug_dir.exists():
        return

    cutoff_time = time.time() - (max_age_days * 24 * 60 * 60)
    deleted_count = 0
    bytes_freed = 0

    for debug_file in debug_dir.iterdir():
        try:
            stat = debug_file.stat()
            if stat.st_mtime < cutoff_time:
                size = stat.st_size
                if debug_file.is_file():
                    debug_file.unlink()
                elif debug_file.is_dir():
                    import shutil
                    shutil.rmtree(debug_file, ignore_errors=True)
                deleted_count += 1
                bytes_freed += size
        except OSError:
            continue

    if deleted_count > 0:
        mb_freed = bytes_freed / (1024 * 1024)
        log_debug(
            "Cleaned up old debug files",
            hook_name="session-snapshot",
            parsed_data={"deleted": deleted_count, "mb_freed": round(mb_freed, 1)},
        )
        print(f"[session-cleanup] Removed {deleted_count} old debug file(s), freed {mb_freed:.1f} MB")


def _cleanup_session_env() -> None:
    """Clean up empty session-env directories."""
    session_env_dir = Path.home() / ".claude" / "session-env"
    if not session_env_dir.exists():
        return

    deleted_count = 0
    for session_dir in session_env_dir.iterdir():
        try:
            if session_dir.is_dir() and not any(session_dir.iterdir()):
                session_dir.rmdir()
                deleted_count += 1
        except OSError:
            continue

    if deleted_count > 0:
        log_debug(
            "Cleaned up empty session-env directories",
            hook_name="session-snapshot",
            parsed_data={"deleted": deleted_count},
        )
        print(f"[session-cleanup] Removed {deleted_count} empty session-env dir(s)")


if __name__ == "__main__":
    main()
